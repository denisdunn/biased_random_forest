# biased_random_forest
Headline: Biased random forest coded from scratch with new class imbalance technique

INTRO: Following this scientific paper: https://ieeexplore.ieee.org/document/8541100, I built the biased random forest described in this paper. The main gist of the paper is the creation of a new technique for handling class imbalance inside of the algorithm instead of during the preprocessing stage. The focus of the paper is on the critical regions in the dataset which are considered the datapoints from each class that are closest together in a knn means metric. This area of the dataset  is considered to be the toughest areas to predict, and a double dip into this area to handle class imbalance could improve the model.

EXPLORATORY DATA ANALYSIS: There are 768 data points in the data with 9 different features. Unfortunately in the Insulin category 374 rows had zeros, and in the skin thickness category 227 rows had zeros. The paper doesn't explain how they handle this issue, so I use the mean average of each column to fill in the missing data. I didn't want to do anything exotic and change the results of the experiment.

CLASS IMBALANCE TECHNIQUE: The paper goes on to explain that the critical areas in the dataset can be used in the bagging method of a random forest. To help counter overfitting, the randomness of a decision tree forest has to do with how the dataset is sampled. The model is designed to construct (S) number of trees using a feature removal process. During that process, features are removed from the splitting aspect of the decision tree. The effect is a construction of different trees built from using a different combination of features in the dataset. With this forest of random trees, each tree has a different perspective of the data and can help vote on the predicted class. I then add a sub sampling of the forest (bagging) to further combat overfitting and help garner a more robust group vote. During this sampling, the paper instructed me to create half of the forest sampling in a normal random process, while the other half focuses on generating a sampling of the critical (difficult) areas of the dataset. The sampling consists of the full minority class and their closest k neighbors in the majority class. Using kmeans to find the nearest neighbors I also have the ability to tune the number of neighbors in the sampling which will improve or weaken the disparity in the class imbalances. 

BIASED BAG: The paper designed the sampling for this biased bag to contain the full minority class of data points and a tunable number of the majority class. Using a kmeans process to choose the neighbors, the paper limits the use of each datapoint to only once so there are no duplicate majority members in the bag. I used 10 as the number of nearest neighbors from the paper and recieved a class imbalance with more majority datapoints, but with a much smaller imbalance. This bag is now considered the critical bag of datapoints.

BUILDING BIASED RANDOM FOREST: Having to implement these ideas into a random forest model I had to build everything from scratch. Using code from https://machinelearningmastery.com/implement-random-forest-scratch-python/ I was able to achieve most of what I was looking to accomplish. I did have to code the biased bagging process into the forest and code the retrieval of the relevant information to calculate precision,recall, and confidence scores. The metrics used for this paper was an f1score and a gmeans score, but i also wanted to understand the PRC, ROC, AUROC, and AUPRC. 

METRICS: After coding the model to return the predicted,actual and confidence scores. I was able to create precision recall curves, and receiver operator curves for the 10 fold cross validations and the test set. Using the confidence scores I created threshold scoring to calculate the AUPRC and the AUROC for the dataset. As you can see the AUROC is 25% and the AUPRC is 29%, Precision is 67% and Recall is 59%, which explains the model in fuller context.
![Screenshot](https://github.com/denisdunn/biased_random_forest/blob/master/auprc_curve_cross_val.png)
![Screenshot](https://github.com/denisdunn/biased_random_forest/blob/master/auprc_testset.png)


CONCLUSION: When you tak into consideration that the model intentionally samples the very difficult (critical) areas, the precision and recall scores are pretty decent. My F1 score and the gmean scores came in at close to 64%. Below you can see the graphs of the AUPRC % AUROC.


NEXT STEPS: I am going to work on imputing more advanced techniques to fill in the missing data. I also am going to add binary signal columns to see if the missing data in insulin and skin thickness is a signal of anything. Taking into consideration that this experiement and modeling is designed to test a class imbalance technique, the impuation of missing data could potential have big effects on the sampling.
